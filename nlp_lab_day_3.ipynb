{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankuj/teaching/blob/main/nlp_lab_day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhE_ve2CMku1"
      },
      "source": [
        "\n",
        "<br>\n",
        "RNN Practical — Intro to Recurrent Neural Networks<br>\n",
        "Topics: Motivation, Basics, Architectures (One-to-Many, Many-to-One, etc.), Shared Parameters<br>\n",
        "Instructions: Complete each task by filling in the \"Your answer here\" sections.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eut5NBEdMku6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzWjX89mMku-"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 1: RNN Architectures <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlDX2hiTMku-"
      },
      "outputs": [],
      "source": [
        "def task1_architectures():\n",
        "    \"\"\"\n",
        "    Identify the correct RNN architecture (One-to-One, One-to-Many, Many-to-One, Many-to-Many)\n",
        "    for the following scenarios:\n",
        "    a) Sentiment analysis of a sentence -> single label\n",
        "    b) Music generation from a single start token -> output sequence\n",
        "    c) Named entity recognition: tag each word in a sentence\n",
        "    d) Machine translation: source sentence -> target sentence\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    # a) Many-to-One\n",
        "    # b) One-to-Many\n",
        "    # c) Many-to-Many\n",
        "    # d) Many-to-Many (encoder-decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz1xbYovMkvA"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 2: Shared Parameters <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5UlHXaMJMkvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30edbc63-52f4-4cdc-c221-9f4de685f3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "def task2_shared_parameters():\n",
        "    \"\"\"\n",
        "    Explain shared parameters in an RNN.\n",
        "    Compute parameter counts for an example:\n",
        "      input size d=4, hidden size h=3, sequence length T=10\n",
        "    \"\"\"\n",
        "    parameters = 4*3 + 3*3 + 3\n",
        "    return parameters\n",
        "\n",
        "print(task2_shared_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyzZbkLMkvB"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 3: Manual Forward Pass <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nlcGh9oLMkvC"
      },
      "outputs": [],
      "source": [
        "from os import X_OK\n",
        "def task3_manual_forward_pass(x_seq):\n",
        "    \"\"\"\n",
        "    Compute hidden states manually for a small RNN using np.tanh.\n",
        "    Input sequence length T=3, input size=2, hidden size=2\n",
        "    \"\"\"\n",
        "    # x_seq = [np.array([0.5, -1.0]),\n",
        "    #          np.array([1.0, 0.0]),\n",
        "    #          np.array([-0.5, 0.5])]\n",
        "    h_prev = np.zeros(2)\n",
        "    W_xh = np.array([[0.6, -0.2],\n",
        "                     [0.1,  0.5]])\n",
        "    W_hh = np.array([[0.3, 0.4],\n",
        "                     [-0.2, 0.2]])\n",
        "    b_h = np.array([0.0,0.1])\n",
        "    h_list = [h_prev]\n",
        "\n",
        "    # Your code here\n",
        "    for i in range(len(x_seq)):\n",
        "      ht1 = W_hh @ h_list[i]\n",
        "      ht2 = W_xh @ x_seq[i]\n",
        "      ht = np.tanh(ht1 + ht2 + b_h)\n",
        "      h_list.append(ht)\n",
        "\n",
        "    return h_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORsqt1mMkvC"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 4: NumPy RNN Cell Implementation <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lSsfHVNCMkvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5050f1-a725-4899-9659-29ac9fa38088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0.61516023, 0.38483977]), array([0.41120963, 0.58879037]), array([0.5667828, 0.4332172]), array([0.43510336, 0.56489664])]\n"
          ]
        }
      ],
      "source": [
        "def task4_numpy_rnn_cell():\n",
        "    \"\"\"\n",
        "    Implement a simple Many-to-One RNN in NumPy.\n",
        "    Use rnn_forward to compute h_T, then compute a readout: y = W_hy h_T + b_y\n",
        "    Predict class = argmax(y)\n",
        "    \"\"\"\n",
        "\n",
        "    # Toy dataset\n",
        "    toy_sequences = [\n",
        "        [np.array([1.0,0.5]), np.array([0.2,0.1]), np.array([0.3,-0.1])],\n",
        "        [np.array([-0.5,-0.4]), np.array([0.1,-0.2]), np.array([-0.3,-0.1])],\n",
        "        [np.array([0.8,0.2]), np.array([0.5,0.4]), np.array([0.1,0.2])],\n",
        "        [np.array([-0.6,-0.2]), np.array([-0.4,-0.3]), np.array([0.0,-0.1])]\n",
        "    ]\n",
        "    labels = np.array([1,0,1,0])\n",
        "    b_y = np.array([0.0,0.1])\n",
        "\n",
        "    h = 2\n",
        "    c = 2\n",
        "\n",
        "    W_hy = np.random.randn(c,h)\n",
        "    y_s=[]\n",
        "\n",
        "\n",
        "    for x in range(len(toy_sequences)):\n",
        "      h_t = task3_manual_forward_pass(toy_sequences[x])[-1]\n",
        "      y = (W_hy @ h_t + b_y)\n",
        "      softmax_y = np.exp(y) / np.sum(np.exp(y))\n",
        "      y_s.append(softmax_y)\n",
        "    return y_s\n",
        "\n",
        "\n",
        "print(task4_numpy_rnn_cell())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Goal:\n",
        "- Introduction to tensors in PyTorch\n",
        "- Build a simple RNN-based classifier\n",
        "\n",
        "Dataset:\n",
        "- We will classify short sequences of numbers as \"increasing\" or \"decreasing\"\n",
        "  Example:\n",
        "    [1, 2, 3, 4] → Label: 1 (increasing)\n",
        "    [5, 3, 1, 0] → Label: 0 (decreasing)\n",
        "\n",
        "----------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ====================================================\n",
        "# STEP 1: Create a Tiny Synthetic Dataset\n",
        "# ====================================================\n",
        "\n",
        "def generate_data(num_samples=100, seq_len=4):\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(num_samples):\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            seq = torch.sort(torch.rand(seq_len))[0]   # Increasing\n",
        "            label = 1\n",
        "        else:\n",
        "            seq = torch.sort(torch.rand(seq_len), descending=True)[0]  # Decreasing\n",
        "            label = 0\n",
        "        X.append(seq.unsqueeze(-1))  # Shape: (seq_len, input_size=1)\n",
        "        y.append(label)\n",
        "    return torch.stack(X), torch.tensor(y)\n",
        "\n",
        "X, y = generate_data()\n",
        "# X shape → (batch_size=100, seq_len=4, input_size=1)\n",
        "# y shape → (batch_size=100)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 2: Define a Simple RNN Classifier\n",
        "# ====================================================\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=8, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out, h_n = self.rnn(x)\n",
        "        logits = self.fc(out[:, -1, :])\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = RNNClassifier()\n",
        "print(model)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 3: Train the Model\n",
        "# ====================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# STEP 4: Test the Model on New Data\n",
        "# ====================================================\n",
        "\n",
        "test_X, test_y = generate_data(num_samples=10)\n",
        "\n",
        "print(\"\\nPredictions vs Actual:\")\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(test_X)\n",
        "    _, predicted = torch.max(test_outputs.data, 1)\n",
        "\n",
        "    for i in range(len(test_y)):\n",
        "        print(f\"Sequence: {test_X[i].squeeze().tolist()}, Predicted: {predicted[i].item()}, Actual: {test_y[i].item()}\")"
      ],
      "metadata": {
        "id": "Nxyi_7bfR1vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d28ee5-b797-4164-8ace-9dda2726b6a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNClassifier(\n",
            "  (rnn): RNN(1, 8, batch_first=True)\n",
            "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n",
            "Epoch [10/100], Loss: 0.5799\n",
            "Epoch [20/100], Loss: 0.3751\n",
            "Epoch [30/100], Loss: 0.1004\n",
            "Epoch [40/100], Loss: 0.0373\n",
            "Epoch [50/100], Loss: 0.0230\n",
            "Epoch [60/100], Loss: 0.0170\n",
            "Epoch [70/100], Loss: 0.0140\n",
            "Epoch [80/100], Loss: 0.0119\n",
            "Epoch [90/100], Loss: 0.0104\n",
            "Epoch [100/100], Loss: 0.0093\n",
            "\n",
            "Predictions vs Actual:\n",
            "Sequence: [0.09198939800262451, 0.3211410641670227, 0.5555521249771118, 0.9068019390106201], Predicted: 1, Actual: 1\n",
            "Sequence: [0.29357975721359253, 0.42326390743255615, 0.4981306195259094, 0.9300925731658936], Predicted: 1, Actual: 1\n",
            "Sequence: [0.9191019535064697, 0.6401392817497253, 0.6161629557609558, 0.2959928512573242], Predicted: 0, Actual: 0\n",
            "Sequence: [0.20755892992019653, 0.3255099058151245, 0.6439730525016785, 0.6946362257003784], Predicted: 1, Actual: 1\n",
            "Sequence: [0.03713345527648926, 0.19796228408813477, 0.3342568278312683, 0.5729206800460815], Predicted: 1, Actual: 1\n",
            "Sequence: [0.09922969341278076, 0.28273266553878784, 0.5595453381538391, 0.6067126393318176], Predicted: 1, Actual: 1\n",
            "Sequence: [0.6266231536865234, 0.5594205856323242, 0.24031907320022583, 0.06389635801315308], Predicted: 0, Actual: 0\n",
            "Sequence: [0.5821903944015503, 0.30123454332351685, 0.27575165033340454, 0.22280853986740112], Predicted: 0, Actual: 0\n",
            "Sequence: [0.8445557355880737, 0.6270908117294312, 0.44718843698501587, 0.13120847940444946], Predicted: 0, Actual: 0\n",
            "Sequence: [0.7654049396514893, 0.7036239504814148, 0.1372125744819641, 0.13245230913162231], Predicted: 0, Actual: 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}