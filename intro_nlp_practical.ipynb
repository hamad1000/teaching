{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCUw45mZKjG"
      },
      "source": [
        "Intro to NLP Practical<br>\n",
        "======================<br>\n",
        "Students will work through problems on n-grams, probabilities, OOV handling, and classifiers.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJnSQ_vqZKjO"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2tr5e7WZKjQ"
      },
      "source": [
        "Toy corpus for language modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uJmCM0sZKjS"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Mary had a little lamb\",\n",
        "    \"Its fleece was white as snow\",\n",
        "    \"And everywhere that Mary went\",\n",
        "    \"The lamb was sure to go\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nIvCzEeZKjT"
      },
      "source": [
        "--- Part 1: Preprocessing ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re-DkrvQZKjU"
      },
      "source": [
        " Q1.1 Sequence notation<br>\n",
        "Exercise: Write sequence notation for the sentence:<br>\n",
        "\"Mary had a little lamb, its fleece was white as snow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAOpzABuZKjV"
      },
      "source": [
        " Q1.2 Add start/end tokens<br>\n",
        "Exercise: Write a function to tokenize the corpus and add <s>, </s>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRH1mpV5ZKjY"
      },
      "source": [
        "--- Part 2: N-grams & Probabilities ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVR2UlsZKjZ"
      },
      "source": [
        " Q2.1 Extract unigrams, bigrams, trigrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RuQzfXWZKjb"
      },
      "source": [
        " Q2.2 Bigram probabilities<br>\n",
        "Exercise: Write function to compute P(w_i | w_{i-1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3G1JGIAZKjj"
      },
      "source": [
        " Q2.3 Sentence probability<br>\n",
        "Exercise: Compute probability of \"Mary had a little lamb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0unZilSZKjk"
      },
      "source": [
        "Q2.4 Handling OOV/UNK<br>\n",
        "Exercise: Replace unseen words with <UNK> and recompute\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evU5bff_ZKjl"
      },
      "source": [
        "--- Part 3: Classifier ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3DxxnAKZKjm"
      },
      "source": [
        " Q3.1 Naive Bayes sentiment classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìΩ Exercise 3.1: Sentiment Classification on toy dataset\n",
        "\n",
        "In this exercise, you will build a simple sentiment classification model that predicts whether a given sentence is **positive** or **negative**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úèÔ∏è Instructions:\n",
        "\n",
        "\n",
        "### 1Ô∏è‚É£ Perform Feature Extraction\n",
        "- Use **TF-IDF Vectorization** to convert names into numerical features.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ Train a Machine Learning Classifier\n",
        "- Use any classifier you are familiar with (e.g., **Logistic Regression** or **Naive Bayes**).\n",
        "- Split the data into **training** and **testing** sets.\n",
        "- Train the classifier on the training data.\n",
        "\n",
        "\n",
        "üöÄ **Goal:** By the end of this exercise, you should be able to:\n",
        "- Apply **feature extraction** to text data.\n",
        "- Train and evaluate a **text classification model** using **machine learning**."
      ],
      "metadata": {
        "id": "Yyx3z1RL58el"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3fkQ5DUZKjm"
      },
      "outputs": [],
      "source": [
        "train_texts = [\n",
        "    \"I love my dog\",\n",
        "    \"This food is great\",\n",
        "    \"I hate waiting\",\n",
        "    \"The movie was boring\",\n",
        "    \"Happy with my phone\",\n",
        "    \"This is awful\"\n",
        "]\n",
        "train_labels = [\"pos\", \"pos\", \"neg\", \"neg\", \"pos\", \"neg\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìΩ Exercise 3.2: Movie Review Classification using Movies Review Corpus\n",
        "\n",
        "In this exercise, you will build a simple text classification model that predicts whether a given **movie review** is **positive** or **negative** using the **NLTK Movie Reviews Corpus**.\n",
        "\n",
        "This is a classical example of text classification at the **sentence level**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úèÔ∏è Instructions:\n",
        "\n",
        "### 1Ô∏è‚É£ Load the Data\n",
        "- Import the **Movie Reviews corpus** from **NLTK**.\n",
        "- Create a dataset where each example is a review and the label is either `'positive'` or `'negative'`.\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ Perform Feature Extraction\n",
        "- Use **TF-IDF Vectorization** to convert names into numerical features.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 3Ô∏è‚É£ Train a Machine Learning Classifier\n",
        "- Use any classifier you are familiar with (e.g., **Logistic Regression** or **Naive Bayes**).\n",
        "- Split the data into **training** and **testing** sets.\n",
        "- Train the classifier on the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### 4Ô∏è‚É£ Evaluate the Classifier\n",
        "- Use **accuracy** and a **classification report** to evaluate your model on the test set.\n",
        "- Think about: How well does the model perform? Which reviews are harder to classify?\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ You are free to explore:\n",
        "- Trying different classifiers.\n",
        "- Visualizing the results (e.g., confusion matrix).\n",
        "\n",
        "---\n",
        "\n",
        "üöÄ **Goal:** By the end of this exercise, you should be able to:\n",
        "- Apply **feature extraction** to text data.\n",
        "- Train and evaluate a **text classification model** using **machine learning**."
      ],
      "metadata": {
        "id": "fq7Vj1ng1lw8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYgyaWtZKju"
      },
      "source": [
        " Q3.3 Discussion: Why bigrams vs unigrams?<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv13VAlzZKju"
      },
      "source": [
        " Q3.4 Limitations of n-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mIB4S3wZKju"
      },
      "source": [
        "--- Part 4: Wrap-up Reflection ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzsTXZsTZKjv"
      },
      "source": [
        " Discussion Questions<br>\n",
        "1. Why do we need <UNK> tokens?<br>\n",
        "2. Why start/end tokens?<br>\n",
        "3. Why not always use higher n-grams?<br>\n",
        "4. How do classifiers differ from language models?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}